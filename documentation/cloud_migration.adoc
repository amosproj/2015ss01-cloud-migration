Cloud Migration
===============


== Migrating an application to the cloud ==

=== Introduction ===

Our task was to migrate a calculator to the cloud. To do so, we took a look at the calculator and figured out that it was a client-side application. So we thought about a way to serve this application from all three cloud providers without having to have a different code base on any of them.
We took a look at the different technologies the clouds provide to find a common base for our application. We figured out that we basically had two possibilities that’d allow a common codebase:

1. Just run a machine without anything pre-installed and run our own server architecture like Apache or Jetty
2. Use python with flask (a web server framework for python)

We decided against using the first possibility for the following reason: It would allow a common codebase, but we’d have to do the setup of the server software. This setup routine would differ from cloud to cloud (for example, azure runs on windows machines while aws provides linux servers). A second reason is that all this setup would’ve caused a lot of time loss. We wanted to figure out a very quick way to run applications in the cloud.

=== Flask Setup ===

All three clouds gave the ability to run python scripts and especially flask applications without a lot of setup.

==== Azure ====

Open up the Azure Portal, click on “New”, “Web + Mobile”, “Azure Marketplace” and search for Flask. Click on the result, click on “Create” and you’re done

==== Google ====
Open up the Developers Console for the Google Cloud Platform, click on ‘create project’. Choose a fitting name, id (in the following we call it ‘id-of-the-project’) and the region for computing, finally click on ‘create project’. You should be relinked to the Project Dashboard. Click on ‘try App Engine’. Choose python and Flask as ‘starter-code’. Now you can follow the steps by google for a quick setup:

* Download the constructed ‘Hello World’ files in a folder. 
* Download and install the Google SDK with the App Engine Package with following commands:
** curl https://sdk.cloud.google.com/ | bash
** gcloud auth login
** gcloud components update gae-python
* Now go to the folder of the project files and call:
** appcfg.py -A ‘id-of-the-project’
** update appengine-try-python-flask

Now the application should be loaded into the cloud. You can access it via:

‘id-of-the-project’.appspot.com

==== AWS ====
Open the AWS Management Console, click on “Elastic Beanstalk” and select “Action” and then “Launch New Environment”. Click on “Create web server”. Then you can select the platform you need and choose if it should be an single instance or with load balancer and auto-scaling. In the next step you can upload a zip-file which contains your application. Afterwards you can name your application by your own. In the last steps you can choose if you want to get access to the virtual instance and other customizing things. But it works very well with the default configuration. At least you start the service with the “Launch” button.

=== Serving the Calculator ===

After this was done, we set up a simple flask application that did nothing but serve the calculator. To do so, we had to adjust a few paths in the calculator (for example, we changed the paths in the index.html from <path> to static/<path>).

At this point, we ran the application on all three clouds, had to do a few adjustments, but quickly reached the goal of running the same application with the same codebase on the three clouds.

Step-by-Step Guide on how to run an application in the cloud using our flask application:

1. Get the Flask application, open the FlaskWebProject folder
2. Put your static files in the static folder. Static files are files like javascript, css, fonts, images and so on
3. Save your html files in the “templates” folder.
4. In the html files, change URLs to static files to the “Jinja” markup language. Example: css/file.css becomes {{ url_for('static', filename=’css/file.css') }}
5. Edit the views.py file. Add routes with:
I) @app.route(‘/myroute’)
II) def my_route():
III)    return render_template(‘my_html_file.html’)
6. Save the cloud-specific config.py file in the root folder of the application.
7. To test your application locally, leave the FlaskWebProject folder and run the runserver.py with python2
8. To deploy it, follow the steps for our deployer (below)

=== The Deployer ===

To make the deployment easier, we wrote an application (cloud_deployer), which is responsible for successfully deploying an application to the cloud.

The deployer has a few requirements:

* Python2 installed
* git installed
* Each cloud needs a few config files - for authentication with the cloud and for usage in the cloud. Those need to be put into the cloud_specific_files/<cloudname>/ folders

If you’ve put everything in place, simply run deployer.py with python2 and follow the instructions on screen


== Information about the Clouds ==

The different clouds were looked at considering the following topics:

Cost, Debugging, Framework specific issues, Deployment (Deploying without deployer), Webinterface, Speed, Database/Storage, Other

=== Azure ===

- *Cost*: Very high. 40€ for one month of rather low usage.
- *Debugging*: Problematic. You can run the application locally (by running runserver.py), but that does not show all of the errors that might happen on the cloud. On-cloud debugging is almost impossible - you only get cryptic 500 messages that have nothing to do with your application itself, just with a framework layer that azure provides.
- *Framework specific issues*: Does not allow .json files in the root folder. If you deploy an application (like ours) that has a .json file in the root folder, azure tries to deploy it as a node.js application, not as a python application.
- *Deployment*: Azure allows multiple ways to deploy your application. You can deploy by just uploading it via ftp, by committing and pushing to a git repository or by using continuous deployment via github or similar.
- *Webinterface*: Very user-friendly. You get to the features you need most often really fast. Some of the rarely used features are hidden though (for example, “Troubleshoot” and “Diagnostic Logs” are in different tabs, both hard to find)
- *Speed*: Takes a while for the instances to start. Should not be a problem if the page is used often, but if azure decides to shut down the instances, you need to wait for a long time.
- *Database/Storage*: Azure does not provide mysql databases itself, but they have an interface to a different mysql hosting provider that is included in their web-interface. Azure blob storage is easy to use and provides a lot of different ways to access it for both read and write operations. There is a python package that allows simple access to their API (the “azure” package), but you can also just use a REST API access point if your language of choice is not supported.
- *Other*: Support is rather hard to get. Found no way to get support for azure without having to use the credentials given by DATEV.

=== AWS ===

- *Cost*: Very low in our case. Works with the Pay-as-you-go Price concept. There are different sizes of instances with different costs. In our case we use the smallest instance for free and have only costs for the storage. (Costs May: 0,04 €) 
- *Debugging*: Very useful. You have the possibility to get the logs very easy over the management console in Elastic Beanstalk. You can choose between the last 100 lines of logs in the browser or download a zip-file with the whole log content. In the case with the last 100 lines you can easily find bugs while you deploy the application.
- *Framework specific issues*: The python start script of the flask application has to be named “application.py” otherwise an error will occour. 
- *Deployment*: AWS has develop a Command Line Interface for Elastic Beanstalk which allows you to deploy your application very comfortable. It`s available for Linux, Mac Os and Windows. The command line tool help you step by step to deploy your application to AWS. In the first step you will create with “eb init” a configuration file in a hidden folder which has the name “.elasticbeanstalk”. The configuration contains the destination region, the application name, the deploy platform, the region on aws. 
- *Webinterface*: The interface is not very intuitive. If you have no experience with the AWS Management console you will need some time to reach the things you want. But after some time the structure of the webinterface make sense and it works well.
- *Speed*: The speed depends on the size of the instance. In our case we use a micro instance and it takes ca. 5 minutes to start the hole instance the first time with application. (Anmerkung über Loadbalancer fehlt noch…)
- *Database/Storage*: AWS provide MySQL, Oracle DB, SQL Server, PostgreSQL and Amazon Aurora. As a result the user has nearly every database possibility. Amazon has a Storage solution, too. It`s called Amazon S3. Every user can create up to 100 buckets where he can store his data. Over the python framework boto, the user has the possibility to administrate the storage. This framework allows the user to create/update/delete buckets, upload/download over various ways and set the relevant permissions to files.
- *Other*: N/A

=== Google ===

- *Cost*: Very low with our application. Works with the Pay-as-you-go Price concept. Like in AWS there are different sizes of instances. Also the App Engine, which we are using only bills per used CPU-time, therefore the costs scale with the usage. (Costs May: <1€) 
- *Debugging*: You can either Debug locally with the Google Development Dever or you can access the logs in the Developers Console. These include normal messaging and stack traces. Filtering for specific timeframes and other feature deemed very useful. You can ‘export’ your logs, which are actually streaming your logs to the BigQuery dataset, the GCS bucket and/or the Pub/Sub topic. These can be accessed via other applications.
- *Framework specific issues*: Frameworks served by google need to be included in app.yaml, but third-party libraries needs to be included by installing the library to a folder and adjusting the system-path-variable in appengine_config.py
If more than 1 person wants to upload the app, you have to add these people into your project via the developers console. Otherwise if you are uploading with the same account, you'll get uploading collisions.
- *Deployment*:  Google allows multiple ways to deploy your application. You can deploy with the Google Cloud Tool ‘gcloud’. There you can install packages for every service and use these for deploying your app. 
- *Webinterface*: Design is very good. Though for first-time Users not too Intuitive. Without explanation what some feature are doing, you can either experience via ‘try and error’ and pay or you have to read the explanation what this feature/service is doing by google. Though if you know what you are doing the Interface is mostly very good. Though some features are hidden well, like assigning an ip4-address to your Google Storage Service.
- *Speed*: Takes only about 1 second for the instances to start. Google starts, dependent on the usage more instance and also shuts them down, if they are not needed anymore.
- *Database/Storage*: To Access one of the Storage Services by Google, in either the Compute or App Engine, you have to setup a Service account there. Also you need encryption files, generated by google if you want to use your Application locally. Generally there are different ways to save something in the Google-cloud: BigTable, Datastore, SQL and Storage. BigTable is used for Big Data. Datastore is saving Data with noSQL, SQL saves via MySQL and Storage uses the Bucket System common for Cloud Services. We currently use SQL and Storage.
- *Other*: The specific case for HTML delivery can be also be done via the Google Storage Service. You upload your files to 1 Bucket and adjust the settings for the bucket to be a HTML-Web-Service. But this approach only works for static files, no backend PHP, Python, etc. scripting. Therefore not compatible with User-Authentification.
